{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac00df7-cee7-4dae-829f-b4bc54e4ebd0",
   "metadata": {},
   "source": [
    "# Enschede NDVI Update Pipeline: Multi-Year Zonal Statistics in PostGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d69c9e9-fd11-41b1-b061-636f8520e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pystac_client import Client\n",
    "from shapely.geometry import shape\n",
    "import rioxarray as rxr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from sqlalchemy import text, create_engine\n",
    "import psycopg\n",
    "import mapclassify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d988b6-a971-4785-a9b9-969bc9682c71",
   "metadata": {},
   "source": [
    "## Inputs: Yearly NDVI Composites\n",
    "### Loading Enschede Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29b9010-6669-4de4-b5c6-9fb15c893682",
   "metadata": {},
   "outputs": [],
   "source": [
    "enschede = gpd.read_file('../../vector/data/enschede_boundary.gpkg')\n",
    "enschede_4326 = enschede.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf3c5f-7e23-44d0-adee-b228164d5df5",
   "metadata": {},
   "source": [
    "### Connecting to Element 84's Earth Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db79e706-21b4-4f96-b997-87cacaacdeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client.open('https://earth-search.aws.element84.com/v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa70b7f-fc5e-435b-9bab-df53efa6cb49",
   "metadata": {},
   "source": [
    "### Setting the Yearly Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdf8faef-aac8-4843-88d2-12463403a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2024', '2019']\n",
    "years.sort()\n",
    "\n",
    "enschede_clip = enschede_4326.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35fba2e-46dd-455b-b3c1-85807704d42a",
   "metadata": {},
   "source": [
    "### Exporting the Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e9fabc2-0f66-4610-8f84-9d79a5ec1116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported S2B_32ULC_20190826_0_L2A\n",
      "Exported S2B_32ULC_20190826_1_L2A\n",
      "Exported S2B_32ULC_20190627_0_L2A\n",
      "Exported S2B_32ULC_20190627_1_L2A\n",
      "Exported S2A_32ULC_20190513_1_L2A\n",
      "Exported S2A_32ULC_20190513_0_L2A\n",
      "Exported S2B_32ULC_20190329_0_L2A\n",
      "Exported S2B_32ULC_20190329_1_L2A\n",
      "Exported S2B_32ULC_20190227_0_L2A\n",
      "Exported ndvi_composite_2019.tif\n",
      "Exported S2B_32ULC_20240720_0_L2A\n",
      "Exported S2A_32ULC_20240625_0_L2A\n",
      "Exported S2A_32ULC_20240127_0_L2A\n",
      "Exported ndvi_composite_2024.tif\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "        \n",
    "    # Creating the Search Query\n",
    "    search = client.search(\n",
    "        collections=['sentinel-2-l2a'],\n",
    "        intersects=enschede_4326['geometry'].iloc[0],\n",
    "        datetime=f'{year}',\n",
    "        query=['eo:cloud_cover<5']\n",
    "    )\n",
    "    \n",
    "    items = search.item_collection()\n",
    "    \n",
    "    # Filtering for Images Covering Enschede\n",
    "    total_images = gpd.GeoDataFrame(\n",
    "        [\n",
    "            {\n",
    "                'item': item,\n",
    "                'geometry': shape(item.geometry),\n",
    "            }\n",
    "            for item in items\n",
    "        ],\n",
    "        crs=enschede_4326.crs\n",
    "    )\n",
    "    \n",
    "    enschede_images = total_images[total_images['geometry'].covers(enschede_4326['geometry'].iloc[0])]\n",
    "    \n",
    "    for item in enschede_images['item']:\n",
    "            \n",
    "        # Loading Single Bands\n",
    "        assets = item.assets\n",
    "        \n",
    "        red = rxr.open_rasterio(assets['red'].href, masked=True).squeeze()\n",
    "        \n",
    "        if enschede_clip.crs != red.rio.crs:\n",
    "            enschede_clip = enschede_clip.to_crs(red.rio.crs)\n",
    "            \n",
    "        red = red.rio.clip(enschede_clip.geometry.values, enschede_clip.crs, drop=True)\n",
    "        \n",
    "        nir = rxr.open_rasterio(assets['nir'].href, masked=True).squeeze()\n",
    "        nir = nir.rio.clip(enschede_clip.geometry.values, enschede_clip.crs, drop=True)\n",
    "        \n",
    "        # Building an NDVI Raster\n",
    "        ndvi = (nir - red) / (nir + red)\n",
    "    \n",
    "        ndvi = ndvi.rio.reproject(enschede.crs)\n",
    "        ndvi = ndvi.where(np.isfinite(ndvi), -9999)\n",
    "        ndvi = ndvi.rio.write_nodata(-9999)\n",
    "    \n",
    "        # Exporting the Raster\n",
    "        inputs_folder = Path(f'../data/{year}/inputs')\n",
    "        input_file_name = f'ndvi_{item.id}.tif'\n",
    "        input_file = Path(inputs_folder/input_file_name)\n",
    "        input_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if input_file.exists():\n",
    "            input_file.unlink()\n",
    "        \n",
    "        ndvi.rio.to_raster(input_file, driver='GTiff')\n",
    "        print(f'Exported {item.id}')\n",
    "    \n",
    "    # Stacking Input Rasters\n",
    "    rasters = [\n",
    "        rxr.open_rasterio(file, masked=True).squeeze()\n",
    "        for file in inputs_folder.iterdir()\n",
    "        if file.is_file()\n",
    "    ]\n",
    "    \n",
    "    rasters_concat = xr.concat(rasters, dim='time')\n",
    "\n",
    "    # Computing Median Composites\n",
    "    composite = rasters_concat.median(dim='time')\n",
    "    composite = composite.where(np.isfinite(composite), -9999)\n",
    "    composite = composite.rio.write_nodata(-9999)\n",
    "    \n",
    "    # Exporting Results\n",
    "    composite_folder = Path(f'../data/{year}/composite')\n",
    "    composite_file_name = f'ndvi_composite_{year}.tif'\n",
    "    composite_file = Path(composite_folder/composite_file_name)\n",
    "    composite_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if composite_file.exists():\n",
    "        composite_file.unlink()\n",
    "    \n",
    "    composite.rio.to_raster(composite_file, driver='GTiff')\n",
    "    print(f'Exported {composite_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b5ec7-6bfe-4397-aa87-f113c2e47664",
   "metadata": {},
   "source": [
    "## Inputs: Yearly District Zonal Statistics\n",
    "### Loading Districts into PostGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f49d69-16ba-4791-b875-c03b3576bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    'postgresql+psycopg://postgres:postgres@localhost/postgres'\n",
    ")\n",
    "\n",
    "districts = gpd.read_file(f'../../vector/data/enschede_districts.gpkg')\n",
    "\n",
    "districts.to_postgis(\n",
    "    'districts',\n",
    "    engine,\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b811851-886a-44f4-aeec-90d5f85385e6",
   "metadata": {},
   "source": [
    "### Loading the Yearly Composites into PostGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81eed369-d595-4b2e-b773-92492f95dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for year in years:\n",
    "#    f\"!raster2pgsql \\\n",
    "#    -I \\\n",
    "#    -C \\\n",
    "#    -M \\\n",
    "#    -t 256x256 \\\n",
    "#    ../data/{year}/composite/ndvi_composite_{year}.tif public.ndvi_{year} \\\n",
    "#    | psql -U postgres -d postgres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61498e-cce2-4cd5-a84b-8e1ad9b161cb",
   "metadata": {},
   "source": [
    "### Tiling Rasters and Building Spatial Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a841afa-8186-4471-b0ee-1a1e00094563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(\n",
    "            text(\n",
    "                f\"\"\"\n",
    "                DROP TABLE IF EXISTS ndvi_tiles_{year};\n",
    "    \n",
    "                CREATE TABLE ndvi_tiles_{year} AS\n",
    "                SELECT rid,\n",
    "                ST_Tile(rast, 256, 256) AS rast\n",
    "                FROM ndvi_{year};\n",
    "    \n",
    "                CREATE INDEX IF NOT EXISTS idx_{year}\n",
    "                ON ndvi_tiles_{year}\n",
    "                USING GIST(ST_ConvexHull(rast));\n",
    "                \"\"\"\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a901461-8ed7-457b-a88d-6c71cf1937f1",
   "metadata": {},
   "source": [
    "### Computing Zonal Stats per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "716a819f-a31a-4397-8176-6caf89d25f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported zonal_stats_2019.geojson\n",
      "Exported zonal_stats_2024.geojson\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(\n",
    "            text(\n",
    "                f\"\"\"\n",
    "                DROP TABLE IF EXISTS ndvi_stats_{year};\n",
    "                \n",
    "                CREATE TABLE ndvi_stats_{year} AS\n",
    "                \n",
    "                SELECT d.district_code,\n",
    "                d.geometry,\n",
    "                ROUND((j.stats).min::numeric, 2) as min_ndvi,\n",
    "                ROUND((j.stats).max::numeric, 2) as max_ndvi,\n",
    "                ROUND((j.stats).mean::numeric, 2) as mean_ndvi\n",
    "                \n",
    "                FROM districts as d\n",
    "                JOIN LATERAL (\n",
    "                \n",
    "                    SELECT ST_SummaryStatsAgg(ST_Clip(\n",
    "                        t.rast,\n",
    "                        d.geometry,\n",
    "                        true),\n",
    "                        1,\n",
    "                        true\n",
    "                    ) AS stats\n",
    "                    FROM ndvi_tiles_{year} AS t\n",
    "                    WHERE ST_ConvexHull(t.rast) && d.geometry\n",
    "                    AND ST_Intersects(t.rast, d.geometry)\n",
    "                    \n",
    "                ) AS j\n",
    "                \n",
    "                ON true;\n",
    "                \"\"\"            \n",
    "            )\n",
    "        )\n",
    "\n",
    "    stats = gpd.read_postgis(\n",
    "        f\"\"\"\n",
    "        SELECT *\n",
    "        FROM ndvi_stats_{year}\n",
    "        ORDER BY district_code;\n",
    "        \"\"\",\n",
    "        engine,\n",
    "        crs=enschede.crs,\n",
    "        geom_col='geometry'\n",
    "    )\n",
    "    \n",
    "    stats = stats.to_crs(enschede_4326.crs)\n",
    "    \n",
    "    stats_folder = Path(f'../data/{year}/stats')\n",
    "    stats_file = Path(f'zonal_stats_{year}.geojson')\n",
    "    stats_path = Path(stats_folder/ stats_file)\n",
    "    stats_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    stats.to_file(stats_path, driver='GeoJSON')\n",
    "    \n",
    "    print(f'Exported {stats_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f48413-2387-4f42-85c6-dc67ec9355cc",
   "metadata": {},
   "source": [
    "## Updating the Zonal Statistics Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fdfec29-1b40-4424-9aad-b2d72212a9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported ndvi_stats_latest.geojson\n"
     ]
    }
   ],
   "source": [
    "# Initialising the latest table\n",
    "if not years:\n",
    "    raise ValueError('years list is empty')\n",
    "\n",
    "init_year = years[0]\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(\n",
    "        text(\n",
    "            f\"\"\"\n",
    "            DROP TABLE IF EXISTS ndvi_stats_latest;\n",
    "\n",
    "            CREATE TABLE ndvi_stats_latest AS\n",
    "            \n",
    "            SELECT *\n",
    "            FROM ndvi_stats_{init_year};\n",
    "            \"\"\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Updating changed fields from newer years\n",
    "for year in years[1:]:\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(\n",
    "            text(\n",
    "                f\"\"\"\n",
    "                \n",
    "                UPDATE ndvi_stats_latest AS a\n",
    "                    SET min_ndvi = CASE\n",
    "                                            WHEN a.min_ndvi != b.min_ndvi\n",
    "                                            THEN b.min_ndvi\n",
    "                                            ELSE a.min_ndvi\n",
    "                                      END,\n",
    "\n",
    "                         max_ndvi = CASE\n",
    "                                            WHEN a.max_ndvi != b.max_ndvi\n",
    "                                            THEN b.max_ndvi\n",
    "                                            ELSE a.max_ndvi\n",
    "                                      END,\n",
    "                         mean_ndvi = CASE\n",
    "                                            WHEN a.mean_ndvi!= b.mean_ndvi\n",
    "                                            THEN b.mean_ndvi\n",
    "                                            ELSE a.mean_ndvi\n",
    "                                       END\n",
    "\n",
    "                \n",
    "                FROM ndvi_stats_{year} AS b\n",
    "                WHERE a.district_code = b.district_code;\n",
    "                \"\"\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "latest_ndvi = gpd.read_postgis(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM ndvi_stats_latest\n",
    "    ORDER BY district_code;\n",
    "    \"\"\",\n",
    "    engine,\n",
    "    crs=enschede.crs,\n",
    "    geom_col='geometry'\n",
    ")\n",
    "\n",
    "# Exporting the latest snapshot as a GeoJSON file\n",
    "latest_ndvi = latest_ndvi.to_crs(enschede_4326.crs)\n",
    "\n",
    "latest_folder = Path('../data/latest')\n",
    "latest_file = Path('ndvi_stats_latest.geojson')\n",
    "latest_path = Path(latest_folder/ latest_file)\n",
    "latest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "latest_ndvi.to_file(latest_path, driver='GeoJSON')\n",
    "print(f'Exported {latest_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b9cf7-b5a9-4dfe-9908-ee016e6550b1",
   "metadata": {},
   "source": [
    "## Calculating Classification Breaks for Web Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a3e4848-ad9f-47b9-83c0-e4da83918acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification breaks: [0.38 0.46 0.61 0.73] \n",
      "\n",
      "Descriptive statistics for the mean_ndvi field: \n",
      "count    10.000000\n",
      "mean      0.516000\n",
      "std       0.110675\n",
      "min       0.360000\n",
      "25%       0.445000\n",
      "50%       0.535000\n",
      "75%       0.557500\n",
      "max       0.730000\n",
      "Name: mean_ndvi, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ndvi_stats_latest = gpd.read_file(latest_path)\n",
    "\n",
    "bins = mapclassify.NaturalBreaks(ndvi_stats_latest['mean_ndvi'], k=4).bins\n",
    "print(f'Classification breaks: {bins} \\n')\n",
    "\n",
    "desc_stats = ndvi_stats_latest['mean_ndvi'].describe()\n",
    "print(f'Descriptive statistics for the mean_ndvi field: \\n{desc_stats}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
