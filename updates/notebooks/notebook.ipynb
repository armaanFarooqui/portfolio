{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aac00df7-cee7-4dae-829f-b4bc54e4ebd0",
   "metadata": {},
   "source": [
    "# Updating Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d69c9e9-fd11-41b1-b061-636f8520e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pystac_client import Client\n",
    "from shapely.geometry import shape\n",
    "import rioxarray as rxr\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from geocube.api.core import make_geocube\n",
    "from sqlalchemy import text, create_engine\n",
    "import psycopg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d988b6-a971-4785-a9b9-969bc9682c71",
   "metadata": {},
   "source": [
    "## Loading Enschede Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29b9010-6669-4de4-b5c6-9fb15c893682",
   "metadata": {},
   "outputs": [],
   "source": [
    "enschede = gpd.read_file('../../vector/data/enschede_boundary.gpkg')\n",
    "enschede_4326 = enschede.to_crs('EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bf3c5f-7e23-44d0-adee-b228164d5df5",
   "metadata": {},
   "source": [
    "## Connecting to Element 84's Earth Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db79e706-21b4-4f96-b997-87cacaacdeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client.open('https://earth-search.aws.element84.com/v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa70b7f-fc5e-435b-9bab-df53efa6cb49",
   "metadata": {},
   "source": [
    "## Setting the Yearly Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf8faef-aac8-4843-88d2-12463403a4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2024', '2019']\n",
    "years.sort()\n",
    "\n",
    "enschede_clip = enschede_4326.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35fba2e-46dd-455b-b3c1-85807704d42a",
   "metadata": {},
   "source": [
    "## Creating Yearly Median Composite Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e9fabc2-0f66-4610-8f84-9d79a5ec1116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported S2B_32ULC_20240720_0_L2A\n",
      "Exported S2A_32ULC_20240625_0_L2A\n",
      "Exported S2A_32ULC_20240127_0_L2A\n",
      "Exported ndvi_composite_2024.tif\n",
      "Exported S2B_32ULC_20190826_0_L2A\n",
      "Exported S2B_32ULC_20190826_1_L2A\n",
      "Exported S2B_32ULC_20190627_0_L2A\n",
      "Exported S2B_32ULC_20190627_1_L2A\n",
      "Exported S2A_32ULC_20190513_1_L2A\n",
      "Exported S2A_32ULC_20190513_0_L2A\n",
      "Exported S2B_32ULC_20190329_0_L2A\n",
      "Exported S2B_32ULC_20190329_1_L2A\n",
      "Exported S2B_32ULC_20190227_0_L2A\n",
      "Exported ndvi_composite_2019.tif\n"
     ]
    }
   ],
   "source": [
    "years = ['2024', '2019']\n",
    "\n",
    "for year in years:\n",
    "        \n",
    "    search = client.search(\n",
    "        collections=['sentinel-2-l2a'],\n",
    "        intersects=enschede_4326['geometry'].iloc[0],\n",
    "        datetime=f'{year}',\n",
    "        query=['eo:cloud_cover<5']\n",
    "    )\n",
    "    \n",
    "    items = search.item_collection()\n",
    "    \n",
    "    total_images = gpd.GeoDataFrame(\n",
    "        [\n",
    "            {\n",
    "                'item': item,\n",
    "                'geometry': shape(item.geometry),\n",
    "            }\n",
    "            for item in items\n",
    "        ],\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    enschede_images = total_images[total_images['geometry'].covers(enschede_4326['geometry'].iloc[0])]\n",
    "    \n",
    "    for item in enschede_images['item']:\n",
    "            \n",
    "        assets = item.assets\n",
    "        \n",
    "        red = rxr.open_rasterio(assets['red'].href, masked=True).squeeze()\n",
    "        \n",
    "        if enschede_clip.crs != red.rio.crs:\n",
    "            enschede_clip = enschede_clip.to_crs(red.rio.crs)\n",
    "            \n",
    "        red = red.rio.clip(enschede_clip.geometry.values, enschede_clip.crs, drop=True)\n",
    "        \n",
    "        nir = rxr.open_rasterio(assets['nir'].href, masked=True).squeeze()\n",
    "        nir = nir.rio.clip(enschede_clip.geometry.values, enschede_clip.crs, drop=True)\n",
    "        \n",
    "        ndvi = (nir - red) / (nir + red)\n",
    "    \n",
    "        ndvi = ndvi.where(np.isfinite(ndvi), -9999)\n",
    "        ndvi = ndvi.rio.write_nodata(-9999)\n",
    "    \n",
    "        inputs_folder = Path(f'../data/{year}/inputs')\n",
    "        input_file_name = f'ndvi_{item.id}.tif'\n",
    "        input_file = Path(inputs_folder/input_file_name)\n",
    "        input_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if input_file.exists():\n",
    "            input_file.unlink()\n",
    "        \n",
    "        ndvi.rio.to_raster(input_file, driver='GTiff')\n",
    "        print(f'Exported {item.id}')\n",
    "    \n",
    "    rasters = [\n",
    "        rxr.open_rasterio(file, masked=True)\n",
    "        for file in inputs_folder.iterdir()\n",
    "        if file.is_file()\n",
    "    ]\n",
    "    \n",
    "    rasters_concat = xr.concat(rasters, dim='time')\n",
    "    composite = rasters_concat.median(dim='time')\n",
    "    \n",
    "    composite = composite.where(np.isfinite(composite), -9999)\n",
    "    composite = composite.rio.write_nodata(-9999)\n",
    "    \n",
    "    composite_folder = Path(f'../data/{year}/composite')\n",
    "    composite_file_name = f'ndvi_composite_{year}.tif'\n",
    "    composite_file = Path(composite_folder/composite_file_name)\n",
    "    composite_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if composite_file.exists():\n",
    "        composite_file.unlink()\n",
    "    \n",
    "    composite.rio.to_raster(composite_file, driver='GTiff')\n",
    "    print(f'Exported {composite_file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a1087-c88d-4dbb-b821-773e1588b50f",
   "metadata": {},
   "source": [
    "## Updating Database Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "94c71be8-866b-44fd-ae26-624ba3b23ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported latest.csv\n"
     ]
    }
   ],
   "source": [
    "if not years:\n",
    "    raise ValueError('years list is empty')\n",
    "\n",
    "init_year = years[0]\n",
    "baseline_df = pd.read_csv(f'../data/{init_year}/stats/zonal_stats_{init_year}.csv')\n",
    "\n",
    "value_columns = [\n",
    "    column\n",
    "    for column in baseline_df.columns\n",
    "    if column != 'sn'\n",
    "]\n",
    "\n",
    "for year in years[1:]:\n",
    "    comparision_df = pd.read_csv(f'../data/{year}/stats/zonal_stats_{year}.csv')\n",
    "\n",
    "    merged_df = baseline_df.merge(\n",
    "        comparision_df,\n",
    "        on='sn',\n",
    "        suffixes=('_base', '_new')\n",
    "    )\n",
    "\n",
    "    for column in value_columns:\n",
    "        baseline_df[column] = merged_df[f'{column}_new'].where(\n",
    "            merged_df[f'{column}_new'] != merged_df[f'{column}_base'],\n",
    "            merged_df[f'{column}_base']\n",
    "        )\n",
    "\n",
    "latest_folder = Path('../data/latest')\n",
    "latest_file = 'latest.csv'\n",
    "latest_file_path = Path(latest_folder/ latest_file)\n",
    "latest_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "baseline_df.to_csv(latest_file_path, index=False)\n",
    "print(f'Exported {latest_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b5ec7-6bfe-4397-aa87-f113c2e47664",
   "metadata": {},
   "source": [
    "## Calculating Zonal Statistics for Enschede Districts\n",
    "### Connecting to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cee95b-b7c5-4e23-9141-7d40291b0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\n",
    "    'postgresql+psycopg://postgres:postgres@localhost/postgres'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e908df4-3a1a-476c-a39c-267211b18b88",
   "metadata": {},
   "source": [
    "### Importing the Enschede Districts GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9f49d69-16ba-4791-b875-c03b3576bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = gpd.read_file(f'../../vector/data/enschede_districts.gpkg')\n",
    "\n",
    "districts.to_postgis(\n",
    "    'districts',\n",
    "    engine,\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b811851-886a-44f4-aeec-90d5f85385e6",
   "metadata": {},
   "source": [
    "### Importing the Composites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81eed369-d595-4b2e-b773-92492f95dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for year in years:\n",
    "#    f\"!raster2pgsql \\\n",
    "#    -I \\\n",
    "#    -C \\\n",
    "#    -M \\\n",
    "#    -t 256x256 \\\n",
    "#    ../data/{year}/composite/ndvi_composite_2019.tif public.ndvi_{year} \\\n",
    "#    | psql -U postgres -d postgres\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee61498e-cce2-4cd5-a84b-8e1ad9b161cb",
   "metadata": {},
   "source": [
    "### Creating Tile Layers and Spatial Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a841afa-8186-4471-b0ee-1a1e00094563",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(\n",
    "            text(\n",
    "                f\"\"\"\n",
    "                DROP TABLE IF EXISTS ndvi_tiles_{year};\n",
    "    \n",
    "                CREATE TABLE ndvi_tiles_{year} AS\n",
    "                SELECT rid,\n",
    "                ST_Tile(rast, 256, 256) AS rast\n",
    "                FROM ndvi_{year};\n",
    "    \n",
    "                CREATE INDEX IF NOT EXISTS idx\n",
    "                ON ndvi_tiles_{year}\n",
    "                USING GIST(ST_ConvexHull(rast));\n",
    "                \"\"\"\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a901461-8ed7-457b-a88d-6c71cf1937f1",
   "metadata": {},
   "source": [
    "### Exporting the Zonal Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "716a819f-a31a-4397-8176-6caf89d25f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported zonal_stats_2019.geojson\n",
      "Exported zonal_stats_2024.geojson\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    \n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(\n",
    "            text(\n",
    "                f\"\"\"\n",
    "                DROP TABLE IF EXISTS ndvi_stats_{year};\n",
    "                \n",
    "                CREATE TABLE ndvi_stats_{year} AS\n",
    "                \n",
    "                SELECT d.district_code,\n",
    "                d.geometry,\n",
    "                ROUND((j.stats).min::numeric, 2) as min_ndvi,\n",
    "                ROUND((j.stats).max::numeric, 2) as max_ndvi,\n",
    "                ROUND((j.stats).mean::numeric, 2) as mean_ndvi\n",
    "                \n",
    "                FROM districts as d\n",
    "                JOIN LATERAL (\n",
    "                \n",
    "                    SELECT ST_SummaryStatsAgg(ST_Clip(\n",
    "                        t.rast,\n",
    "                        d.geometry,\n",
    "                        true),\n",
    "                        1,\n",
    "                        true\n",
    "                    ) AS stats\n",
    "                    FROM ndvi_tiles_2019 AS t\n",
    "                    WHERE t.rast && d.geometry AND ST_Intersects(t.rast, d.geometry)\n",
    "                    \n",
    "                ) AS j\n",
    "                \n",
    "                ON true;\n",
    "                \"\"\"            \n",
    "            )\n",
    "        )\n",
    "\n",
    "    stats = gpd.read_postgis(\n",
    "        f\"\"\"\n",
    "        SELECT *\n",
    "        FROM ndvi_stats_{year};\n",
    "        \"\"\",\n",
    "        engine,\n",
    "        crs='EPSG:28992',\n",
    "        geom_col='geometry'\n",
    "    )\n",
    "    \n",
    "    stats = stats.to_crs('EPSG:4326')\n",
    "    \n",
    "    stats_folder = Path(f'../data/{year}/stats')\n",
    "    stats_file = Path(f'zonal_stats_{year}.geojson')\n",
    "    stats_path = Path(stats_folder/ stats_file)\n",
    "    stats_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    stats.to_file(stats_path, driver='GeoJSON')\n",
    "    \n",
    "    print(f'Exported {stats_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f48413-2387-4f42-85c6-dc67ec9355cc",
   "metadata": {},
   "source": [
    "## Creating the Latest NDVI Stats DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b03fe-7d7e-4eda-9270-2cfc19491481",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not years:\n",
    "    raise ValueError(\"years list is empty\")\n",
    "\n",
    "init_year = years[0]\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f\"\"\"\n",
    "        DROP TABLE IF EXISTS ndvi_stats_latest;\n",
    "        CREATE TABLE ndvi_stats_latest AS\n",
    "        SELECT *\n",
    "        FROM ndvi_stats_{init_year};\n",
    "    \"\"\"))\n",
    "\n",
    "    for year in years[1:]:\n",
    "        conn.execute(text(f\"\"\"\n",
    "            UPDATE ndvi_stats_latest AS b\n",
    "            SET\n",
    "                min_ndvi = CASE\n",
    "                    WHEN c.min_ndvi <> b.min_ndvi THEN c.min_ndvi\n",
    "                    ELSE b.min_ndvi\n",
    "                END,\n",
    "                max_ndvi = CASE\n",
    "                    WHEN c.max_ndvi <> b.max_ndvi THEN c.max_ndvi\n",
    "                    ELSE b.max_ndvi\n",
    "                END,\n",
    "                mean_ndvi = CASE\n",
    "                    WHEN c.mean_ndvi <> b.mean_ndvi THEN c.mean_ndvi\n",
    "                    ELSE b.mean_ndvi\n",
    "                END\n",
    "            FROM ndvi_stats_{year} AS c\n",
    "            WHERE b.district_code = c.district_code;\n",
    "        \"\"\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
